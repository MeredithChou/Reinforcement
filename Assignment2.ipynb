{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwcnBnFIKsTowFq3O2l4yv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeredithChou/Reinforcement/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1yL4LlyQdq1",
        "outputId": "562bfb57-96aa-48ff-9ed0-8890ef348c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym) (1.22.4)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym) (6.4.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgWX9MPWQOg3",
        "outputId": "6d124177-7d90-4c67-e51b-bad2dc78f260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial state: 414\n",
            "State space:  Discrete(500)\n",
            "Action space:  Discrete(6)\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import gymnasium\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "env = gym.make(\"Taxi-v3\", render_mode = \"rgb_array\")\n",
        "state= env.reset()\n",
        "\n",
        "print(\"Initial state:\", state)\n",
        "print(\"State space: \", env.observation_space)\n",
        "print(\"Action space: \", env.action_space)\n",
        "\n",
        "DOWN = 0\n",
        "UP = 1\n",
        "RIGHT = 2\n",
        "LEFT = 3\n",
        "PICKUP = 4\n",
        "DROPOFF = 5\n",
        "\n",
        "\n",
        "#There are 500 discrete states since there are 25 taxi positions, 5 possible locations of the passenger (including the case when the passenger is in the taxi), and 4 destination locations."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_q(agent, env, n_episodes, max_steps=10000):\n",
        "    step = 0\n",
        "    steps = np.zeros(n_episodes) # Steps after each episode\n",
        "    total_rewards = np.zeros(n_episodes)\n",
        "    for i in range(n_episodes):\n",
        "        rewards=0\n",
        "        terminated = False\n",
        "        truncated = False\n",
        "        state = env.reset()\n",
        "        while not terminated and not truncated:\n",
        "            action = agent.act(state)\n",
        "            state_next, reward, terminated, truncated = env.step(action)\n",
        "            agent.learn(state, action, reward, state_next,i)\n",
        "            state = state_next\n",
        "            step += 1\n",
        "            rewards += reward\n",
        "            \n",
        "            if step>max_steps:\n",
        "                return steps, rewards\n",
        "        steps[i] = step\n",
        "        total_rewards[i] = rewards\n",
        "        \n",
        "    print(agent.Q[422,:])\n",
        "    print(agent.Q[8,:])\n",
        "    print(agent.Q[209,:])\n",
        "    print(agent.Q[227,:])\n",
        "    print(agent.Q[386,:])\n",
        "    return total_rewards, steps"
      ],
      "metadata": {
        "id": "b8TWlFCxQXDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QAgent():\n",
        "    def __init__(self, n_states, n_actions, gamma, alpha, epsilon):\n",
        "        self.n_states = n_states\n",
        "        self.n_actions = n_actions\n",
        "        self.alpha = 0.1\n",
        "        self.gamma = 1\n",
        "        self.epsilon = 0\n",
        "        self.Q = np.zeros((n_states, n_actions))\n",
        "        self.Qtables = np.zeros((n_states, n_actions+1))\n",
        "        \n",
        "        for i in range(0,500):\n",
        "            self.Qtables[i,0] = i\n",
        "        \n",
        "        \n",
        "    def act(self, state):\n",
        "        # Implement the self.epsilon-greedy policy\n",
        "        rand = np.random.rand()\n",
        "#         if np.random.rand() > self.epsilon: \n",
        "        if rand > self.epsilon: \n",
        "#             print(f\"rand: {rand}, self.epsilon: {self.epsilon}\")\n",
        "            action = np.argmax(self.Q[state,:]) \n",
        "#             print(f\"Now: rand > epsilon , This state action array: {self.Q[state,:]}, will take action: {action}\")\n",
        "        else: \n",
        "#             print(f\"rand: {rand}, self.epsilon: {self.epsilon}\")\n",
        "            action = np.random.choice(self.n_actions) \n",
        "#             print(f\"Now: rand < epsilon , Can selete action from {self.n_actions} ways, will take action: {action}\")\n",
        "            \n",
        "        return action\n",
        "            \n",
        "    def learn(self, s, a, r, s_next,i):\n",
        "        # Implement the Q-learning update\n",
        "        Q_next = np.max(self.Q[s_next,:]) \n",
        "        self.Q[s,a] += self.alpha*(r + self.gamma*Q_next - self.Q[s,a]) \n",
        "        \n",
        "#         if i == 50:\n",
        "#             print(i,self.Q[283,:])"
      ],
      "metadata": {
        "id": "zsIPo-yQQY9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env_train = gym.make(\"Taxi-v3\")\n",
        "agentQ = QAgent(env.observation_space.n, env.action_space.n, gamma=1, alpha=0.1, epsilon=0)"
      ],
      "metadata": {
        "id": "DkQBFFMqQbnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = train_q(agentQ, env_train, n_episodes=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsFJT2lzRIDj",
        "outputId": "b38b6ce3-c895-413a-cf8d-3f26b9a7c618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-6.         -5.99619936 -6.12500962 -6.         -6.         -6.        ]\n",
            "[-4.99997588 -5.         -5.07537815 -5.         -5.         -5.        ]\n",
            "[-2.99999994 -3.00166143 -3.08228234 -3.         -3.         -3.        ]\n",
            "[-6.00476157 -5.99405593 -5.95348923 -5.97511311 -6.         -6.        ]\n",
            "[-4.00823301 -3.9999934  -4.         -4.12445905 -4.         -4.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P1lVWK5ZRJrb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}